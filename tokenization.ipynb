{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
ADAD   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  \n",
      "[nltk_data] Downloading package words to /Users/kapeleshh/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import nltk\n",
    "import neologdn\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('words')\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "eng_words = set(nltk.corpus.words.words())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set Seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEED = 13\n",
    "np.random.seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "filepath = \"/Users/kapeleshh/PycharmProjects/STS/\"\n",
    "df =  pd.read_csv(filepath + \"data/preproc_train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data for Japanese stopwords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "file1 = open(\"stopwords/Japanese_stopword_list.txt\")\n",
    "\n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "stopJa = line.split()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sudachi Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tokenizer_obj = dictionary.Dictionary().create()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set mode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "mode = tokenizer.Tokenizer.SplitMode.C #(Mode = B or C)\n",
    "# B - Med\n",
    "# C - NE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Surface tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#dfs = df[:25]\n",
    "for i in range(dfs.shape[0]):\n",
    "    a = dfs.iloc[i].to_string()\n",
    "    a = neologdn.normalize(a)\n",
    "    dfs['text'][i] = [m.surface() for m in tokenizer_obj.tokenize(a, mode)]\n",
    "    dfs['text'][i]= [w for w in dfs['text'][i] if(re.findall(r\"([a-zA-Z]+)\",w) or re.findall(r\"([ぁ-んァ-ン]+)\",w) or re.findall(r\"([一-龯]+)\",w) or re.findall(r\"(\\d+)\",w)) ]\n",
    "    dfs['text'][i] = [word for word in dfs['text'][i] if word not in sw_spacy and word not in string.punctuation and word not in stopJa]\n",
    " #  dfs['text'][i] = [word for word in dfs['text'][i] if word.lower() in eng_words or not word.isalpha()]\n",
    "    dfs['text'][i] = ' '.join(dfs['text'][i]).split()\n",
    "    #dfs.text = dfs.text.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "    #dfs = dfs.dropna(dfs)\n",
    "#   dfs['text'][i]  = words\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Normalized Tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(dfn.shape[0]):\n",
    "    a = dfn.iloc[i].to_string()\n",
    "    dfn['text'][i] = [m.normalized_form() for m in tokenizer_obj.tokenize(a, mode)]\n",
    "    dfn['text'][i] = [word.lower() for word in dfn['text'][i]]\n",
    "    dfn['text'][i] = [word for word in dfn['text'][i] if word not in sw_spacy and word not in string.punctuation and word not in stopJa]\n",
    "    dfn['text'][i] = ' '.join(dfn['text'][i]).split()\n",
    "#   dfn['text'][i]  = words\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "dfs.to_csv(filepath + 'data/Ctoken_surface_train.csv', mode = 'w', index=False)\n",
    "dfS.to_pickle(filepath + 'data/Ctoken_surface_train')\n",
    "#dfn.to_csv(filepath + 'data/Ctoken_normal_train.csv', mode = 'w', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}