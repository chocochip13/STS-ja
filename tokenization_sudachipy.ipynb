{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "Sudachtokenization.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "k8loPaxYyXKj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628068323646,
     "user_tz": -330,
     "elapsed": 29753,
     "user": {
      "displayName": "KANNUSAMY S KAPELESHH be15b012",
      "photoUrl": "",
      "userId": "02598409683794241244"
     }
    },
    "outputId": "3de37ea9-f0ed-4061-e186-0d8cb9f60da8"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QK9N11iXy0oJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628068261158,
     "user_tz": -330,
     "elapsed": 65146,
     "user": {
      "displayName": "KANNUSAMY S KAPELESHH be15b012",
      "photoUrl": "",
      "userId": "02598409683794241244"
     }
    },
    "outputId": "7da303c0-13e6-4c93-9fbc-354a8e55020e"
   },
   "source": [
    "! pip install sudachipy\n",
    "! pip install sudachidict_core\n",
    "! pip install neologdn"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting sudachipy\n",
      "  Downloading SudachiPy-0.5.2.tar.gz (70 kB)\n",
      "\u001B[K     |████████████████████████████████| 70 kB 3.2 MB/s \n",
      "\u001B[?25hCollecting sortedcontainers~=2.1.0\n",
      "  Downloading sortedcontainers-2.1.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting dartsclone~=0.9.0\n",
      "  Downloading dartsclone-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (473 kB)\n",
      "\u001B[K     |████████████████████████████████| 473 kB 18.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from dartsclone~=0.9.0->sudachipy) (0.29.23)\n",
      "Building wheels for collected packages: sudachipy\n",
      "  Building wheel for sudachipy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sudachipy: filename=SudachiPy-0.5.2-cp37-cp37m-linux_x86_64.whl size=870254 sha256=1fd9f75e48d0dce1e5e0976c29ef37825e02a43612702a7f7c1c3b32a56c11e7\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/72/0f/1c62895bde30566c65602f15ddbfa0b2bbc273f8c43c190a45\n",
      "Successfully built sudachipy\n",
      "Installing collected packages: sortedcontainers, dartsclone, sudachipy\n",
      "  Attempting uninstall: sortedcontainers\n",
      "    Found existing installation: sortedcontainers 2.4.0\n",
      "    Uninstalling sortedcontainers-2.4.0:\n",
      "      Successfully uninstalled sortedcontainers-2.4.0\n",
      "Successfully installed dartsclone-0.9.0 sortedcontainers-2.1.0 sudachipy-0.5.2\n",
      "Collecting sudachidict_core\n",
      "  Downloading SudachiDict-core-20210608.tar.gz (9.1 kB)\n",
      "Requirement already satisfied: SudachiPy~=0.5.0 in /usr/local/lib/python3.7/dist-packages (from sudachidict_core) (0.5.2)\n",
      "Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.7/dist-packages (from SudachiPy~=0.5.0->sudachidict_core) (2.1.0)\n",
      "Requirement already satisfied: dartsclone~=0.9.0 in /usr/local/lib/python3.7/dist-packages (from SudachiPy~=0.5.0->sudachidict_core) (0.9.0)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from dartsclone~=0.9.0->SudachiPy~=0.5.0->sudachidict_core) (0.29.23)\n",
      "Building wheels for collected packages: sudachidict-core\n",
      "  Building wheel for sudachidict-core (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sudachidict-core: filename=SudachiDict_core-20210608-py3-none-any.whl size=71421461 sha256=b6026bdd2ba257fbb1dcccad8629ac53bdf72ac83d9ed0fcf6f62bbab20f86e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/3e/74/0beaa92bc46b8d5c14b53d2640f8c3d74cbb33b4ec1fc6c213\n",
      "Successfully built sudachidict-core\n",
      "Installing collected packages: sudachidict-core\n",
      "Successfully installed sudachidict-core-20210608\n",
      "Collecting neologdn\n",
      "  Downloading neologdn-0.5.1.tar.gz (57 kB)\n",
      "\u001B[K     |████████████████████████████████| 57 kB 1.7 MB/s \n",
      "\u001B[?25hBuilding wheels for collected packages: neologdn\n",
      "  Building wheel for neologdn (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for neologdn: filename=neologdn-0.5.1-cp37-cp37m-linux_x86_64.whl size=172990 sha256=c3ded7394fefc367fbb4e180a4562d2b5c78c42f72c5adba1c18438481a110ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/15/5c/55b33d02e16129ef81313e4c86e473d6dd1cecf7317a525a9b\n",
      "Successfully built neologdn\n",
      "Installing collected packages: neologdn\n",
      "Successfully installed neologdn-0.5.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "vJPXQ34iyFZE"
   },
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MW_m2g_CyFZJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628068573576,
     "user_tz": -330,
     "elapsed": 2550,
     "user": {
      "displayName": "KANNUSAMY S KAPELESHH be15b012",
      "photoUrl": "",
      "userId": "02598409683794241244"
     }
    },
    "outputId": "8f2b8692-a110-4acf-e201-335f6411655b"
   },
   "source": [
    "import pandas as pd\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import nltk\n",
    "import neologdn\n",
    "import numpy as np\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('words')\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "eng_words = set(nltk.corpus.words.words())"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/kapeleshh/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7t77CgA_T9DR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628068573585,
     "user_tz": -330,
     "elapsed": 14,
     "user": {
      "displayName": "KANNUSAMY S KAPELESHH be15b012",
      "photoUrl": "",
      "userId": "02598409683794241244"
     }
    }
   },
   "source": [
    "en_alphabets = ['o','q','w','e','r','t','y','u','i','p','a','s','d','f','g','h','j','k','l','z','x','c','v','b','n','m']\n",
    "sw_spacy.update(en_alphabets)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "omvYvO-gyFZK"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "oCGnDrksyFZL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628068592388,
     "user_tz": -330,
     "elapsed": 18815,
     "user": {
      "displayName": "KANNUSAMY S KAPELESHH be15b012",
      "photoUrl": "",
      "userId": "02598409683794241244"
     }
    }
   },
   "source": [
    "filepath = \"/Users/kapeleshh/PycharmProjects/STS/\"\n",
    "df=  pd.read_csv(filepath + \"data/preproc_train.csv\")\n",
    "#df = pd.read_csv(filepath + \"data/Ctoken_train.csv\")"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "OiHnm9UNyFZL"
   },
   "source": [
    "### Load Data for Japanese stopwords"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "H23WMxImyFZM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628068602937,
     "user_tz": -330,
     "elapsed": 427,
     "user": {
      "displayName": "KANNUSAMY S KAPELESHH be15b012",
      "photoUrl": "",
      "userId": "02598409683794241244"
     }
    }
   },
   "source": [
    "file1 = open(filepath + \"stopwords/Japanese_stopword_list.txt\")\n",
    "\n",
    "# Use this to read file content as a stream:\n",
    "line = file1.read()\n",
    "stopJa = line.split()"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "rRNXiYP1yFZN"
   },
   "source": [
    "### Sudachi Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "oZpJ5MvfyFZN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1628068603610,
     "user_tz": -330,
     "elapsed": 3,
     "user": {
      "displayName": "KANNUSAMY S KAPELESHH be15b012",
      "photoUrl": "",
      "userId": "02598409683794241244"
     }
    }
   },
   "source": [
    "def surface_sudachitokens(df):\n",
    "    tokenizer_obj = dictionary.Dictionary().create()\n",
    "    mode = tokenizer.Tokenizer.SplitMode.C #(Mode = B or C)\n",
    "    for i in range(df.shape[0]):\n",
    "        a = df.iloc[i].to_string()\n",
    "        a = neologdn.normalize(a)\n",
    "        df['text'][i] = [m.surface() for m in tokenizer_obj.tokenize(a, mode)]\n",
    "        print(i)\n",
    "    return df\n",
    "\n",
    "def normalized_sudachitokens(df):\n",
    "    tokenizer_obj = dictionary.Dictionary().create()\n",
    "    mode = tokenizer.Tokenizer.SplitMode.C #(Mode = B or C)\n",
    "    for i in range(df.shape[0]):\n",
    "        a = df.iloc[i].to_string()\n",
    "        a = neologdn.normalize(a)\n",
    "        df['text'][i] = [m.normalized() for m in tokenizer_obj.tokenize(a, mode)]\n",
    "        print(i)\n",
    "    return df\n",
    "\n",
    "def stopwords_removal(df, en_stopwords, ja_stopwords, en_dictionary):\n",
    "    for i in range(df.shape[0]):\n",
    "        #df['text'][i]= [w for w in df['text'][i] if(re.findall(r\"([a-zA-Z]+)\",w) or re.findall(r\"([ぁ-んァ-ン]+)\",w) or re.findall(r\"([一-龯]+)\",w) or re.findall(r\"(\\d+)\",w)) or w.lower() in eng_words]\n",
    "        df['text'][i]= [w for w in df['text'][i] if(re.findall(r\"([ぁ-んァ-ン]+)\",w) or re.findall(r\"([一-龯]+)\",w) or re.findall(r\"(\\d+)\",w)) or w.lower() in en_dictionary or not w.isalpha()]\n",
    "        df['text'][i]= [w for w in df['text'][i] if(re.findall(r\"([a-zA-Z]+)\",w) or re.findall(r\"([ぁ-んァ-ン]+)\",w) or re.findall(r\"([一-龯]+)\",w) or re.findall(r\"(\\d+)\",w))]\n",
    "        df['text'][i] = [word for word in df['text'][i] if word not in en_stopwords and word not in string.punctuation and word not in ja_stopwords]\n",
    " #      df['text'][i] = [word for word in df['text'][i] if word.lower() in eng_words or not word.isalpha()]\n",
    "        df['text'][i] = ' '.join(df['text'][i]).split()\n",
    "        print(i)\n",
    "    df.text = df.text.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "    return df"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "surface_sudachitokens(dfs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/kapeleshh/.conda/envs/STS/lib/python3.7/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 text\n0                                                 NaN\n1                                         [りょう, むりょう]\n2                                                 NaN\n3                    [つぼみ, つい, ちいさく, くさっ, もう, かい, ませ]\n4                                                 NaN\n..                                                ...\n95  [そんな, よく, そんな, よく, そんな, よく, そんな, よく, そんな, よく, ...\n96  [いい, いい, いい, いい, いい, いい, いい, いい, いい, いい, いい, い...\n97  [うまうま, うまうま, うまうま, うまうま, うまうま, うまうま, うまうま, うまう...\n98                                              [グッド]\n99                                     [どい, けど, たのしみ]\n\n[100 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[りょう, むりょう]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[つぼみ, つい, ちいさく, くさっ, もう, かい, ませ]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>[そんな, よく, そんな, よく, そんな, よく, そんな, よく, そんな, よく, ...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>[いい, いい, いい, いい, いい, いい, いい, いい, いい, いい, いい, い...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>[うまうま, うまうま, うまうま, うまうま, うまうま, うまうま, うまうま, うまう...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>[グッド]</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>[どい, けど, たのしみ]</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_removal(dfs, sw_spacy, stopJa, eng_words)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}